knitr::opts_chunk$set(echo = TRUE)
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=99),tidy=TRUE)
options(width = 99)
install.packages("inTrees")
install.packages("inTrees")
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=99),tidy=TRUE)
options(width = 99)
# Initialization
packages <- c("tidyverse","readxl","scales","mice","randomForest","MASS","caret","klaR","xlsx","modelr","kernlab") # add any packages that need to be installed to this vec.
checkPackage <- function(package_vec){                 # defining a custom function for checking packages.
for (p in package_vec){
if(p %in% rownames(installed.packages()) == FALSE){
cat(paste(p,"Package is not found/installed on this machine,                  installing the required package... \n"))
install.packages(p,dependencies = TRUE) # Installing with dependancies
} else {
cat(paste("[",p,"]","is present. \n"))
}
}
}
checkPackage(packages) # running check
# Load packages
library('MASS')
library('readxl') # Reading data
library('scales') # visualization
library('dplyr') # data manipulation (already loaded with Tidyverse)
library('mice') # needed for possible imputation
library('randomForest') # RF classification algorithm
library('tidyverse') # Data manipulation + Visualization
library('klaR') # for partimat function for plotting discriminant analysis plots
library('xlsx') # writing to xlsx format
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=99),tidy=TRUE)
options(width = 99)
# Initialization
packages <- c("tidyverse","readxl","scales","mice","randomForest","MASS","caret","klaR","xlsx","modelr","kernlab") # add any packages that need to be installed to this vec.
checkPackage <- function(package_vec){                 # defining a custom function for checking packages.
for (p in package_vec){
if(p %in% rownames(installed.packages()) == FALSE){
cat(paste(p,"Package is not found/installed on this machine,                  installing the required package... \n"))
install.packages(p,dependencies = TRUE) # Installing with dependancies
} else {
cat(paste("[",p,"]","is present. \n"))
}
}
}
checkPackage(packages) # running check
# Load packages
library('MASS')
library('readxl') # Reading data
library('scales') # visualization
library('dplyr') # data manipulation (already loaded with Tidyverse)
library('mice') # needed for possible imputation
library('randomForest') # RF classification algorithm
library('tidyverse') # Data manipulation + Visualization
library('klaR') # for partimat function for plotting discriminant analysis plots
library('xlsx') # writing to xlsx format
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=99),tidy=TRUE)
options(width = 99)
# Initialization
packages <- c("tidyverse","readxl","scales","mice","randomForest","MASS","caret","klaR","xlsx","modelr","kernlab") # add any packages that need to be installed to this vec.
checkPackage <- function(package_vec){                 # defining a custom function for checking packages.
for (p in package_vec){
if(p %in% rownames(installed.packages()) == FALSE){
cat(paste(p,"Package is not found/installed on this machine,                  installing the required package... \n"))
install.packages(p,dependencies = TRUE) # Installing with dependancies
} else {
cat(paste("[",p,"]","is present. \n"))
}
}
}
checkPackage(packages) # running check
# Load packages
library('MASS')
library('readxl') # Reading data
library('scales') # visualization
library('dplyr') # data manipulation (already loaded with Tidyverse)
library('mice') # needed for possible imputation
library('randomForest') # RF classification algorithm
library('tidyverse') # Data manipulation + Visualization
library('klaR') # for partimat function for plotting discriminant analysis plots
library('xlsx') # writing to xlsx format
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=99),tidy=TRUE)
options(width = 99)
# Initialization
packages <- c("tidyverse","readxl","scales","mice","randomForest","MASS","caret","klaR","xlsx","modelr","kernlab") # add any packages that need to be installed to this vec.
checkPackage <- function(package_vec){                 # defining a custom function for checking packages.
for (p in package_vec){
if(p %in% rownames(installed.packages()) == FALSE){
cat(paste(p,"Package is not found/installed on this machine,                  installing the required package... \n"))
install.packages(p,dependencies = TRUE) # Installing with dependancies
} else {
cat(paste("[",p,"]","is present. \n"))
}
}
}
checkPackage(packages) # running check
# Load packages
library('MASS')
library('readxl') # Reading data
library('scales') # visualization
library('dplyr') # data manipulation (already loaded with Tidyverse)
library('mice') # needed for possible imputation
library('randomForest') # RF classification algorithm
library('tidyverse') # Data manipulation + Visualization
library('klaR') # for partimat function for plotting discriminant analysis plots
#library('xlsx') # writing to xlsx format
library('modelr') # for partitioning function
library('caret')
library('kernlab') #Gaussian Process Classification Function
# Loading data (make sure the tables are in the same folder as the rmd)
script_folder <-  getwd() # Retrieving the path from where the rmd is being accessed (To eliminate locating files and paths, if run from the Task folder since default behaviour for getwd in a rmd is to give the working directory of the rmd not the global setting)
occupation_rawdata <- read_excel(paste(getwd(),"/Occupation Data.xlsx",sep = "")) # loading Occupation table
skills_rawdata <-  read_excel(paste(getwd(),"/Skills.xlsx",sep = ""))  # loading Skills table
scale_ref <-  read_excel(paste(getwd(),"/Scales Reference.xlsx",sep = "")) # loading Scales ref table
blsdata <-  read_excel(paste(getwd(),"/national_M2017_dl.xlsx",sep = "")) # national BLS data for general EDA
abilities_rawdata <-  read_excel(paste(getwd(),"/Abilities.xlsx",sep = "")) # loading abilities table
workactivities_rawdata <- read_excel(paste(getwd(),"/Work Activities.xlsx",sep = "")) # loading work activity table
interests_rawdata <- read_excel(paste(getwd(),"/Interests.xlsx",sep = "")) # loading interests table
workstyles_rawdata <- read_excel(paste(getwd(),"/Work Styles.xlsx",sep = ""))
CMR <-  read_excel(paste(getwd(),"/Content Model Reference.xlsx",sep = "")) # Content model Reference details
blsdatamay18 <- blsdata %>% mutate(OCC_CODE = paste(OCC_CODE,".00",sep="")) # BLS data for possible EDA
str(skills_rawdata)
library(tidyverse)
skills <- skills_rawdata %>% select(`O*NET-SOC Code`,Title,`Element Name`,`Scale ID`,`Data Value`)%>%
filter(`Scale ID` == "LV")%>%
spread(key = `Element Name`, value = `Data Value`)
abilities <- abilities_rawdata %>% select(`O*NET-SOC Code`,Title,`Element Name`,`Scale ID`,`Data Value`)%>%                                  filter(`Scale ID` == "LV")%>%
spread(key = `Element Name`, value = `Data Value`)
activities <- workactivities_rawdata %>% select(`O*NET-SOC Code`,Title,`Element Name`,`Scale ID`,`Data Value`)%>%                                  filter(`Scale ID` == "LV")%>%
spread(key = `Element Name`, value = `Data Value`)
interests <- interests_rawdata %>% select(`O*NET-SOC Code`,Title,`Element Name`,`Scale ID`,`Data Value`)%>%                                  filter(`Scale ID` == "OI")%>%
spread(key = `Element Name`, value = `Data Value`)
styles <- workstyles_rawdata %>% select(`O*NET-SOC Code`,Title,`Element Name`,`Scale ID`,`Data Value`)%>%                                  filter(`Scale ID` == "IM")%>%
spread(key = `Element Name`, value = `Data Value`)
merged_features_data <- skills %>% left_join(abilities,by =c("O*NET-SOC Code","Title")) %>% left_join(activities,by =c("O*NET-SOC Code","Title"))  %>% left_join(styles,by =c("O*NET-SOC Code","Title"))  # Joining tables with SOC code as the primary key (title is redundant but kept.)
#-------------------------------------------------------------------------------------------------
features <-  c("O*NET-SOC Code","Title",
"Originality",
"Problem Sensitivity",
"Inductive Reasoning",
"Innovation",
"Analytical Thinking",
"Critical Thinking",
"Active Learning",
"Complex Problem Solving",
"Judging the Qualities of Things, Services, or People",
"Making Decisions and Solving Problems",
"Updating and Using Relevant Knowledge",
"Developing Objectives and Strategies")  # Defining a vector of chosen features
main_features <- merged_features_data %>% dplyr::select(one_of(features)) # picking cols/features of interest.
head(main_features,10)
write_csv(main_features,paste(getwd(),"/TrainingFeatures.csv",sep=""))
Labled_original_data <-  read_csv(paste(getwd(),"/LabledTrainingFeatures.csv",sep = ""), na = "NA")
model_data <- Labled_original_data
names(model_data)<-str_replace_all(names(model_data), c(" " = ".", "," = ""))# renaming cols and removing spaces and commas
str(model_data)
# RandomForest Analysis
rfdata <- model_data %>% drop_na() # doriiping NA rows basically gives us the part of the data that we manually labled.
set.seed(55)  # for reproducibitlity
partitions <- resample_partition(rfdata,c(train = 0.7,test=0.3)) # partitioning labeled data for training & test
train_df <- as.tibble(partitions$train) %>% dplyr::select(-`O*NET-SOC.Code`,-`Title`) # removing title and code from training
test_df <- as.tibble(partitions$test)  # coercing to tibble if train/test need to be viewed.
rf1 <- randomForest(as.factor(ANALYTICAL) ~ . , data = train_df, mtry=12 , ntree = 250, keep.forest=TRUE)
rf1
plot(rf1)
importance(rf1)
# Calculating predictions from train/test of labled data for randomForest
model_test_pred <- test_df %>% mutate("Prediction" = format(predict(rf1,test_df),scientific = FALSE))
model_test_pred_classwise <- test_df %>% mutate("Pred Prob for (0)" = format(predict(rf1,test_df,type = "prob")[,1],scientific = FALSE),
"Pred Prob for (1)" = format(predict(rf1,test_df,type = "prob")[,2],scientific = FALSE)) # adding class probabilities
model_test_pred <- subset(model_test_pred, select=c(`O*NET-SOC.Code`, `Title`,`ANALYTICAL`,`Prediction`,`Originality`:`Developing.Objectives.and.Strategies`)) # reordering columns
model_test_pred_classwise <- subset(model_test_pred_classwise, select=c(`O*NET-SOC.Code`, `Title`,`ANALYTICAL`,`Pred Prob for (0)`,`Pred Prob for (1)`,`Originality`:`Developing.Objectives.and.Strategies`)) # reordering columns
# Displaying Confusion Matrix
Cmatrix1 <- confusionMatrix(as.factor(model_test_pred$Prediction),as.factor(model_test_pred$ANALYTICAL), dnn = c("Prediction", "Reference"),positive='1')
Cmatrix1
cat("The Accuracy is",Cmatrix1$overall["Accuracy"])
# Predicting values for original partially-labled data
model_full_pred <- model_data %>% mutate("Prediction" = format(predict(rf1,model_data),scientific = FALSE)) # predicting on unlabled data
model_full_pred_classwise <- model_data %>% mutate("Pred Prob for (0)" = format(predict(rf1,model_data,type = "prob")[,1],scientific = FALSE),
"Pred Prob for (1)" = format(predict(rf1,model_data,type = "prob")[,2],scientific = FALSE)) # adding class probabilities
model_full_pred <- subset(model_full_pred, select=c(`O*NET-SOC.Code`, `Title`,`ANALYTICAL`,`Prediction`,`Originality`:`Developing.Objectives.and.Strategies`)) # reordering columns
model_full_pred_classwise <- subset(model_full_pred_classwise, select=c(`O*NET-SOC.Code`, `Title`,`ANALYTICAL`,`Pred Prob for (0)`,`Pred Prob for (1)`,`Originality`:`Developing.Objectives.and.Strategies`)) # reordering columns
write.xlsx(model_full_pred,paste(getwd(),"/rfPredResult.xlsx",sep=""))
# Initialization
packages <- c("tidyverse","readxl","scales","mice","randomForest","MASS","caret","klaR","writexl","modelr","kernlab") # add any packages that need to be installed to this vec.
checkPackage <- function(package_vec){                 # defining a custom function for checking packages.
for (p in package_vec){
if(p %in% rownames(installed.packages()) == FALSE){
cat(paste(p,"Package is not found/installed on this machine,                  installing the required package... \n"))
install.packages(p,dependencies = TRUE) # Installing with dependancies
} else {
cat(paste("[",p,"]","is present. \n"))
}
}
}
checkPackage(packages) # running check
# Load packages
library('MASS')
library('readxl') # Reading data
library('scales') # visualization
library('dplyr') # data manipulation (already loaded with Tidyverse)
library('mice') # needed for possible imputation
library('randomForest') # RF classification algorithm
library('tidyverse') # Data manipulation + Visualization
library('klaR') # for partimat function for plotting discriminant analysis plots
library('writexl') # writing to xlsx format
library('modelr') # for partitioning function
library('caret')
library('kernlab') #Gaussian Process Classification Function
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=99),tidy=TRUE)
options(width = 99)
# Initialization
packages <- c("tidyverse","readxl","scales","mice","randomForest","MASS","caret","klaR","writexl","modelr","kernlab") # add any packages that need to be installed to this vec.
checkPackage <- function(package_vec){                 # defining a custom function for checking packages.
for (p in package_vec){
if(p %in% rownames(installed.packages()) == FALSE){
cat(paste(p,"Package is not found/installed on this machine,                  installing the required package... \n"))
install.packages(p,dependencies = TRUE) # Installing with dependancies
} else {
cat(paste("[",p,"]","is present. \n"))
}
}
}
checkPackage(packages) # running check
# Load packages
library('MASS')
library('readxl') # Reading data
library('scales') # visualization
library('dplyr') # data manipulation (already loaded with Tidyverse)
library('mice') # needed for possible imputation
library('randomForest') # RF classification algorithm
library('tidyverse') # Data manipulation + Visualization
library('klaR') # for partimat function for plotting discriminant analysis plots
library('writexl') # writing to xlsx format
library('modelr') # for partitioning function
library('caret')
library('kernlab') #Gaussian Process Classification Function
# Loading data (make sure the tables are in the same folder as the rmd)
script_folder <-  getwd() # Retrieving the path from where the rmd is being accessed (To eliminate locating files and paths, if run from the Task folder since default behaviour for getwd in a rmd is to give the working directory of the rmd not the global setting)
occupation_rawdata <- read_excel(paste(getwd(),"/Occupation Data.xlsx",sep = "")) # loading Occupation table
skills_rawdata <-  read_excel(paste(getwd(),"/Skills.xlsx",sep = ""))  # loading Skills table
scale_ref <-  read_excel(paste(getwd(),"/Scales Reference.xlsx",sep = "")) # loading Scales ref table
blsdata <-  read_excel(paste(getwd(),"/national_M2017_dl.xlsx",sep = "")) # national BLS data for general EDA
abilities_rawdata <-  read_excel(paste(getwd(),"/Abilities.xlsx",sep = "")) # loading abilities table
workactivities_rawdata <- read_excel(paste(getwd(),"/Work Activities.xlsx",sep = "")) # loading work activity table
interests_rawdata <- read_excel(paste(getwd(),"/Interests.xlsx",sep = "")) # loading interests table
workstyles_rawdata <- read_excel(paste(getwd(),"/Work Styles.xlsx",sep = ""))
CMR <-  read_excel(paste(getwd(),"/Content Model Reference.xlsx",sep = "")) # Content model Reference details
blsdatamay18 <- blsdata %>% mutate(OCC_CODE = paste(OCC_CODE,".00",sep="")) # BLS data for possible EDA
str(skills_rawdata)
library(tidyverse)
skills <- skills_rawdata %>% select(`O*NET-SOC Code`,Title,`Element Name`,`Scale ID`,`Data Value`)%>%
filter(`Scale ID` == "LV")%>%
spread(key = `Element Name`, value = `Data Value`)
abilities <- abilities_rawdata %>% select(`O*NET-SOC Code`,Title,`Element Name`,`Scale ID`,`Data Value`)%>%                                  filter(`Scale ID` == "LV")%>%
spread(key = `Element Name`, value = `Data Value`)
activities <- workactivities_rawdata %>% select(`O*NET-SOC Code`,Title,`Element Name`,`Scale ID`,`Data Value`)%>%                                  filter(`Scale ID` == "LV")%>%
spread(key = `Element Name`, value = `Data Value`)
interests <- interests_rawdata %>% select(`O*NET-SOC Code`,Title,`Element Name`,`Scale ID`,`Data Value`)%>%                                  filter(`Scale ID` == "OI")%>%
spread(key = `Element Name`, value = `Data Value`)
styles <- workstyles_rawdata %>% select(`O*NET-SOC Code`,Title,`Element Name`,`Scale ID`,`Data Value`)%>%                                  filter(`Scale ID` == "IM")%>%
spread(key = `Element Name`, value = `Data Value`)
merged_features_data <- skills %>% left_join(abilities,by =c("O*NET-SOC Code","Title")) %>% left_join(activities,by =c("O*NET-SOC Code","Title"))  %>% left_join(styles,by =c("O*NET-SOC Code","Title"))  # Joining tables with SOC code as the primary key (title is redundant but kept.)
#-------------------------------------------------------------------------------------------------
features <-  c("O*NET-SOC Code","Title",
"Originality",
"Problem Sensitivity",
"Inductive Reasoning",
"Innovation",
"Analytical Thinking",
"Critical Thinking",
"Active Learning",
"Complex Problem Solving",
"Judging the Qualities of Things, Services, or People",
"Making Decisions and Solving Problems",
"Updating and Using Relevant Knowledge",
"Developing Objectives and Strategies")  # Defining a vector of chosen features
main_features <- merged_features_data %>% dplyr::select(one_of(features)) # picking cols/features of interest.
head(main_features,10)
write_csv(main_features,paste(getwd(),"/TrainingFeatures.csv",sep=""))
Labled_original_data <-  read_csv(paste(getwd(),"/LabledTrainingFeatures.csv",sep = ""), na = "NA")
model_data <- Labled_original_data
names(model_data)<-str_replace_all(names(model_data), c(" " = ".", "," = ""))# renaming cols and removing spaces and commas
str(model_data)
# RandomForest Analysis
rfdata <- model_data %>% drop_na() # doriiping NA rows basically gives us the part of the data that we manually labled.
set.seed(55)  # for reproducibitlity
partitions <- resample_partition(rfdata,c(train = 0.7,test=0.3)) # partitioning labeled data for training & test
train_df <- as.tibble(partitions$train) %>% dplyr::select(-`O*NET-SOC.Code`,-`Title`) # removing title and code from training
test_df <- as.tibble(partitions$test)  # coercing to tibble if train/test need to be viewed.
rf1 <- randomForest(as.factor(ANALYTICAL) ~ . , data = train_df, mtry=12 , ntree = 250, keep.forest=TRUE)
rf1
plot(rf1)
importance(rf1)
# Calculating predictions from train/test of labled data for randomForest
model_test_pred <- test_df %>% mutate("Prediction" = format(predict(rf1,test_df),scientific = FALSE))
model_test_pred_classwise <- test_df %>% mutate("Pred Prob for (0)" = format(predict(rf1,test_df,type = "prob")[,1],scientific = FALSE),
"Pred Prob for (1)" = format(predict(rf1,test_df,type = "prob")[,2],scientific = FALSE)) # adding class probabilities
model_test_pred <- subset(model_test_pred, select=c(`O*NET-SOC.Code`, `Title`,`ANALYTICAL`,`Prediction`,`Originality`:`Developing.Objectives.and.Strategies`)) # reordering columns
model_test_pred_classwise <- subset(model_test_pred_classwise, select=c(`O*NET-SOC.Code`, `Title`,`ANALYTICAL`,`Pred Prob for (0)`,`Pred Prob for (1)`,`Originality`:`Developing.Objectives.and.Strategies`)) # reordering columns
# Displaying Confusion Matrix
Cmatrix1 <- confusionMatrix(as.factor(model_test_pred$Prediction),as.factor(model_test_pred$ANALYTICAL), dnn = c("Prediction", "Reference"),positive='1')
Cmatrix1
cat("The Accuracy is",Cmatrix1$overall["Accuracy"])
# Predicting values for original partially-labled data
model_full_pred <- model_data %>% mutate("Prediction" = format(predict(rf1,model_data),scientific = FALSE)) # predicting on unlabled data
model_full_pred_classwise <- model_data %>% mutate("Pred Prob for (0)" = format(predict(rf1,model_data,type = "prob")[,1],scientific = FALSE),
"Pred Prob for (1)" = format(predict(rf1,model_data,type = "prob")[,2],scientific = FALSE)) # adding class probabilities
model_full_pred <- subset(model_full_pred, select=c(`O*NET-SOC.Code`, `Title`,`ANALYTICAL`,`Prediction`,`Originality`:`Developing.Objectives.and.Strategies`)) # reordering columns
model_full_pred_classwise <- subset(model_full_pred_classwise, select=c(`O*NET-SOC.Code`, `Title`,`ANALYTICAL`,`Pred Prob for (0)`,`Pred Prob for (1)`,`Originality`:`Developing.Objectives.and.Strategies`)) # reordering columns
write_xlsx(model_full_pred,paste(getwd(),"/rfPredResult.xlsx",sep=""))
write_xlsx(model_full_pred_classwise,paste(getwd(),"/rfPredResult(classwise).xlsx",sep=""))
# Quadratic Discriminant Analysis.
qdadata <- model_data %>% drop_na()
qda.model <- qda(ANALYTICAL ~ . , train_df)
qda.model
partimat(as.factor(ANALYTICAL) ~ Problem.Sensitivity+Analytical.Thinking+Complex.Problem.Solving+Inductive.Reasoning, data = train_df, method="qda")
qda.test <- predict(qda.model,test_df)
test_df$qda <- qda.test$class
Cmatrix2 <- confusionMatrix(as.factor(test_df$qda),as.factor(test_df$ANALYTICAL), dnn = c("Prediction", "Reference"))
Cmatrix2
cat("The Accuracy is",Cmatrix2$overall["Accuracy"])
# Predicting values for original partially-labled data
model_full_pred2 <- model_data %>% mutate("Prediction" = (predict(qda.model,model_data))$class) # predicting on unlabled data
model_full_pred2 <- subset(model_full_pred2, select=c(`O*NET-SOC.Code`, `Title`,`ANALYTICAL`,`Prediction`,`Originality`:`Developing.Objectives.and.Strategies`)) # reordering columns
write_xlsx(model_full_pred2,paste(getwd(),"/QDAPredResult.xlsx",sep=""))
# Gaussian Process Classifier.
gpc_model <- gausspr(as.factor(ANALYTICAL) ~ ., data = train_df, type= 'classification', kernel="anovadot",
kpar="automatic", var=1, variance.model = FALSE, tol=0.0005,
cross=0, fit=TRUE, na.action = na.omit)
(gpc_model)
gpc_data_test <- as.tibble(test_df)
gpc_data_test$Pred <- predict(gpc_model,gpc_data_test[,-3]) # need to remove the response variable from test set before predicting.
# class probabilities
Cmatrix3 <- confusionMatrix(gpc_data_test$Pred,as.factor(gpc_data_test$ANALYTICAL), dnn = c("Prediction", "Reference"))
Cmatrix3
cat("The Accuracy is",Cmatrix3$overall["Accuracy"])
# Predicting values for original partially-labled data
model_full_pred3 <- model_data %>% mutate("Prediction" = format(predict(rf1,model_data),scientific = FALSE)) # predicting on unlabled data
model_full_pred_classwise <- model_data %>% mutate("Pred Prob for (0)" = format(predict(rf1,model_data,type = "prob")[,1],scientific = FALSE),
"Pred Prob for (1)" = format(predict(rf1,model_data,type = "prob")[,2],scientific = FALSE)) # adding class probabilities
model_full_pred3 <- subset(model_full_pred3, select=c(`O*NET-SOC.Code`, `Title`,`ANALYTICAL`,`Prediction`,`Originality`:`Developing.Objectives.and.Strategies`)) # reordering columns
write_xlsx(model_full_pred3,paste(getwd(),"/GPCPredResult.xlsx",sep=""))
ggplot(data = filter(model_full_pred3, !is.na(model_full_pred3$Prediction)))+
geom_bar(aes(x=Prediction,fill = as.factor(Prediction)))
# some data analysis
edadata <-  model_full_pred3
feature_level_ref <-  read_excel(paste(getwd(),"/Level Scale Anchors.xlsx",sep = ""))
feature_level_ref <-  feature_level_ref %>% filter(`Element Name` %in%(features))
edadata$Prediction <- as.integer(edadata$Prediction)
inaccurate <- edadata %>% filter(ANALYTICAL!= Prediction & !is.na(ANALYTICAL))
inaccurate
x <- ggplot(data = filter(edadata, !is.na(model_full_pred3$Prediction)))+
geom_bar(aes(x=Prediction,fill = as.factor(Prediction)))
library(plotly) # comment it out if needed
inaccurate_pred <- inaccurate %>% inner_join(occupation_rawdata, by = c("O*NET-SOC.Code"="O*NET-SOC Code","Title"))
select(inaccurate_pred,Title,Complex.Problem.Solving)
test <- inaccurate %>% gather("Feature", "Value", 5:16) # reshaping the df for plotting
ggplot(data= filter(test, Feature == "Complex.Problem.Solving"),aes(x=Title,y=Value))+
geom_bar(stat = "identity",color="orange")+
aes(stringr::str_wrap(Title, 15)) + xlab(NULL) +
ylab("Complex Problem Solving")
ggplot(data= filter(test, Feature == "Making.Decisions.and.Solving.Problems"),aes(x=Title,y=Value))+
geom_bar(stat = "identity",fill="orange")+
aes(stringr::str_wrap(Title, 15)) + xlab(NULL) +
ylab("Making.Decisions.and.Solving.Problems")
#plotting all feature values
ggplot(dplyr::group_by(test,Title), aes(y=Value, x=Feature ,color=Feature)) +
geom_bar(stat="identity",show.legend = FALSE)+
facet_wrap(.~Title)+
coord_flip()
install.packages("inTrees")
library(inTrees)
library(randomForest)
d
